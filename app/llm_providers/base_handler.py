from abc import ABC, abstractmethod
from typing import Dict, Any, Tuple, Optional
from app.models.config import LLMConfig

class BaseLLMHandler(ABC):
    """Abstract base class for LLM provider handlers."""

    @abstractmethod
    async def generate_text(
        self,
        llm_config: LLMConfig,
        prompt: str,
        context: Dict[str, Any],
        tools: Optional[list] = None
    ) -> Tuple[str, Optional[Dict[str, int]], Optional[str]]:
        """Generate text using the specific LLM provider.

        Args:
            llm_config: The LLM configuration for the node.
            prompt: The fully formatted prompt string to send to the LLM.
            context: The context dictionary, which might be used if the handler needs to
                     construct a more complex message structure (e.g., system prompts).
            tools: Optional list of tool/function definitions for function calling.

        Returns:
            A tuple containing:
                - generated_text (str): The text generated by the LLM.
                - usage (Optional[Dict[str, int]]): A dictionary containing token usage 
                  (e.g., {"prompt_tokens": X, "completion_tokens": Y, "total_tokens": Z}).
                  Return None if usage info is not available.
                - error (Optional[str]): An error message if generation failed, None otherwise.
        """
        pass 